{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , classification_report \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/user/Documents/python_game/model/model/dataset_emotion/train\"\n",
    "test_dir = \"C:/Users/user/Documents/python_game/model/model/dataset_emotion/test\"\n",
    "\n",
    "SEED = 12\n",
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "FINE_TUNING_EPOCHS = 20\n",
    "LR = 0.01\n",
    "NUM_CLASSES = 7\n",
    "EARLY_STOPPING_CRITERIA=3\n",
    "CLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "CLASS_LABELS_EMOJIS = [\"üëø\", \"ü§¢\" , \"üò±\" , \"üòä\" , \"üòê \", \"üòî\" , \"üò≤\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "preprocess_fun = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   rescale = 1./255,\n",
    "                                   validation_split = 0.2,\n",
    "                                   preprocessing_function=preprocess_fun\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2,\n",
    "                                  preprocessing_function=preprocess_fun)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\",\n",
    "                                                    seed = 12\n",
    "                                                   )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                         batch_size = BATCH_SIZE,\n",
    "                                                         shuffle  = True , \n",
    "                                                         color_mode = \"rgb\",\n",
    "                                                         class_mode = \"categorical\",\n",
    "                                                         subset = \"validation\",\n",
    "                                                         seed = 12\n",
    "                                                        )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = False , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def display_one_image(image, title, subplot, color):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16)\n",
    "    \n",
    "def display_nine_images(images, titles, title_colors=None):\n",
    "    subplot = 331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    for i in range(9):\n",
    "        color = 'black' if title_colors is None else title_colors[i]\n",
    "        display_one_image(images[i], titles[i], 331+i, color)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def image_title(label, prediction):\n",
    "  # Both prediction (probabilities) and label (one-hot) are arrays with one item per class.\n",
    "    class_idx = np.argmax(label, axis=-1)\n",
    "    prediction_idx = np.argmax(prediction, axis=-1)\n",
    "    if class_idx == prediction_idx:\n",
    "        return f'{CLASS_LABELS[prediction_idx]} [correct]', 'black'\n",
    "    else:\n",
    "        return f'{CLASS_LABELS[prediction_idx]} [incorrect, should be {CLASS_LABELS[class_idx]}]', 'red'\n",
    "\n",
    "def get_titles(images, labels, model):\n",
    "    predictions = model.predict(images)\n",
    "    titles, colors = [], []\n",
    "    for label, prediction in zip(classes, predictions):\n",
    "        title, color = image_title(label, prediction)\n",
    "        titles.append(title)\n",
    "        colors.append(color)\n",
    "    return titles, colors\n",
    "\n",
    "img_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "img_generator = img_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )\n",
    "clear_output()\n",
    "\n",
    "images, classes = next(img_generator)\n",
    "class_idxs = np.argmax(classes, axis=-1) \n",
    "labels = [CLASS_LABELS[idx] for idx in class_idxs]\n",
    "display_nine_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution (count) among differnt emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig = px.bar(x = CLASS_LABELS_EMOJIS,\n",
    "             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] , \n",
    "             color = np.unique(train_generator.classes) ,\n",
    "             color_continuous_scale=\"Emrld\") \n",
    "fig.update_xaxes(title=\"Emotions\")\n",
    "fig.update_yaxes(title = \"Number of Images\")\n",
    "fig.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Train Data Distribution ',\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(inputs):\n",
    "    feature_extractor = tf.keras.applications.DenseNet169(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights=\"imagenet\")(inputs)\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "def classifier(inputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5) (x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def final_model(inputs):\n",
    "    densenet_feature_extractor = feature_extractor(inputs)\n",
    "    classification_output = classifier(densenet_feature_extractor)\n",
    "    \n",
    "    return classification_output\n",
    "\n",
    "def define_compile_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n",
    "    classification_output = final_model(inputs) \n",
    "    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
    "     \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(0.1), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "model = define_compile_model()\n",
    "clear_output()\n",
    "\n",
    "# Feezing the feature extraction layers\n",
    "model.layers[1].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                         patience=EARLY_STOPPING_CRITERIA,\n",
    "                                                         verbose= 1 ,\n",
    "                                                         restore_best_weights=True\n",
    "                                                        )\n",
    "\n",
    "history = model.fit(x = train_generator,\n",
    "                    epochs = EPOCHS ,\n",
    "                    validation_data = validation_generator , \n",
    "                    callbacks= [earlyStoppingCallback])\n",
    "\n",
    "history = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Un-Freezing the feature extraction layers for fine tuning \n",
    "model.layers[1].trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.001), #lower learning rate\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "history_ = model.fit(x = train_generator,epochs = FINE_TUNING_EPOCHS ,validation_data = validation_generator)\n",
    "history = history.append(pd.DataFrame(history_.history) , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "x = px.line(data_frame= history , y= [\"accuracy\" , \"val_accuracy\"] ,markers = True )\n",
    "x.update_xaxes(title=\"Number of Epochs\")\n",
    "x.update_yaxes(title = \"Accuracy\")\n",
    "x.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Accuracy vs Number of Epochs',\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "x = px.line(data_frame= history , \n",
    "            y= [\"loss\" , \"val_loss\"] , markers = True )\n",
    "x.update_xaxes(title=\"Number of Epochs\")\n",
    "x.update_yaxes(title = \"Loss\")\n",
    "x.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Loss vs Number of Epochs',\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)\n",
    "preds = model.predict(test_generator)\n",
    "y_preds = np.argmax(preds , axis = 1 )\n",
    "y_test = np.array(test_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "cm_data = confusion_matrix(y_test , y_preds)\n",
    "cm = pd.DataFrame(cm_data, columns=CLASS_LABELS, index = CLASS_LABELS)\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.title('Confusion Matrix', fontsize = 20)\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, c_ax = plt.subplots(1,1, figsize = (15,8))\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    for (idx, c_label) in enumerate(CLASS_LABELS):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr,lw=2, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'black',linestyle='dashed', lw=4, label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "print('ROC AUC score:', multiclass_roc_auc_score(y_test , preds  , average = \"micro\"))\n",
    "plt.xlabel('FALSE POSITIVE RATE', fontsize=18)\n",
    "plt.ylabel('TRUE POSITIVE RATE', fontsize=16)\n",
    "plt.legend(fontsize = 11.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC-AUC Score  = \" ,roc_auc_score(to_categorical(y_test) , preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/emotion_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1028436,
     "sourceId": 1732825,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30140,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
